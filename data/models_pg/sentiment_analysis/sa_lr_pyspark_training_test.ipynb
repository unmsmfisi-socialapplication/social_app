{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [TEST] sa_lr_pyspark_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These tests center on functions related to model training and result evaluation in the sa_lr_pyspark_training module.  \n",
    "\n",
    "The primary objective is to ensure that the training and evaluation process is conducted accurately.  \n",
    "\n",
    "The tests include the evaluation of metrics such as the area under the ROC curve, F1 score, and accuracy.  \n",
    "\n",
    "They also verify that training and test DataFrames are generated correctly using the train_test_split function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from training.sa_lr_pyspark_training import train_test_split, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.fixture\n",
    "def spark_session():\n",
    "    # Set up a SparkSession for testing\n",
    "    return SparkSession.builder.master(\"local[2]\").appName(\"test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_test_split(spark_session):\n",
    "    # Create a test DataFrame\n",
    "    data = [\n",
    "        (1, \"This is a sample tweet.\"),\n",
    "        (0, \"Another tweet with numbers 123.\"),\n",
    "    ]\n",
    "    columns = [\"label\", \"text\"]\n",
    "    df = spark_session.createDataFrame(data, columns)\n",
    "\n",
    "    # Call the train_test_split function with the test DataFrame\n",
    "    train_df, test_df = train_test_split(df)\n",
    "\n",
    "    # Verify that the training and testing DataFrames were created correctly\n",
    "    assert train_df.count() > 0\n",
    "    assert test_df.count() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluate_model(spark_session):\n",
    "    # Create a test DataFrame\n",
    "    data = [\n",
    "        (1, 1, \"This is a sample tweet.\"),\n",
    "        (0, 0, \"Another tweet with numbers 123.\"),\n",
    "    ]\n",
    "    columns = [\"label\", \"prediction\", \"features\"]\n",
    "    df = spark_session.createDataFrame(data, columns)\n",
    "\n",
    "    # Call the evaluate_model function with the test DataFrame\n",
    "    result = evaluate_model(df, labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "    # Verify that the results are numbers and within a reasonable range\n",
    "    assert isinstance(result[\"ROC\"], float)\n",
    "    assert 0 <= result[\"ROC\"] <= 1\n",
    "    assert isinstance(result[\"F1\"], float)\n",
    "    assert 0 <= result[\"F1\"] <= 1\n",
    "    assert isinstance(result[\"Accuracy\"], float)\n",
    "    assert 0 <= result[\"Accuracy\"] <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    pytest.main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
