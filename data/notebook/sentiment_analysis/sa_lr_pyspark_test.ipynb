{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [TEST] Parameterize model variables in Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines parameterized variables.\n",
    "fileUrl = \"./twitter.csv\"\n",
    "ID_COLUMN = 'id'\n",
    "LABEL_COLUMN = 'label'\n",
    "TWEET_COLUMN = 'tweet'\n",
    "SEED = 0\n",
    "TRAIN_RATIO = 0.7\n",
    "TEST_RATIO = 0.3\n",
    "MAX_ITER_LR = 15\n",
    "NUM_FOLDS = 8\n",
    "ROC_METRIC_NAME = \"areaUnderROC\"\n",
    "F1_METRIC_NAME = \"f1\"\n",
    "ACCURACY_METRIC_NAME = \"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(fileUrl, spark):\n",
    "    df = spark.read.csv(fileUrl, sep=\",\", inferSchema=True, header=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df):\n",
    "    df = df.withColumnRenamed('_c0', ID_COLUMN).withColumnRenamed('_c1', LABEL_COLUMN).withColumnRenamed('_c2', TWEET_COLUMN)\n",
    "    \n",
    "    df = df.withColumn(TWEET_COLUMN, regexp_replace(TWEET_COLUMN, '[^a-z0-9A-Z`~!@#$%&<>?., ]', ''))\n",
    "    df = df.withColumn(TWEET_COLUMN, regexp_replace(TWEET_COLUMN, '[0-9`~!@#$%&<>?,\\']', ''))\n",
    "    df = df.withColumn(TWEET_COLUMN, regexp_replace(TWEET_COLUMN, 'http://*.*.com', ''))\n",
    "    df = df.withColumn(TWEET_COLUMN, regexp_replace(TWEET_COLUMN, 'www.*.com', ''))\n",
    "    df = df.withColumn(TWEET_COLUMN, regexp_replace(TWEET_COLUMN, '\\.', ''))\n",
    "    \n",
    "    tokenizer = Tokenizer(inputCol=TWEET_COLUMN, outputCol=\"words\")\n",
    "    wordData = tokenizer.transform(df)\n",
    "    \n",
    "    remover = StopWordsRemover(inputCol=\"words\", outputCol=\"word_clean\")\n",
    "    word_clean_data = remover.transform(wordData)\n",
    "    \n",
    "    count = CountVectorizer(inputCol=\"word_clean\", outputCol=\"rawFeatures\")\n",
    "    model = count.fit(word_clean_data)\n",
    "    \n",
    "    featurizedData = model.transform(word_clean_data)\n",
    "    idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "    idfModel = idf.fit(featurizedData)\n",
    "    rescaledData = idfModel.transform(featurizedData)\n",
    "    \n",
    "    return rescaledData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df):\n",
    "    trainDf, testDf = df.randomSplit([TRAIN_RATIO, TEST_RATIO], SEED)\n",
    "    return trainDf, testDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def details_table(train_predictions, test_predictions):\n",
    "    train_predictions.groupBy(LABEL_COLUMN, 'prediction').count().show()\n",
    "    test_predictions.groupBy(LABEL_COLUMN, 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(predictions, labelCol=LABEL_COLUMN, predictionCol=\"prediction\"):\n",
    "    evaluator = BinaryClassificationEvaluator(rawPredictionCol=predictionCol, labelCol=labelCol, metricName=ROC_METRIC_NAME)\n",
    "    roc = evaluator.evaluate(predictions)\n",
    "    \n",
    "    evaluator = MulticlassClassificationEvaluator(predictionCol=predictionCol, labelCol=labelCol, metricName=F1_METRIC_NAME)\n",
    "    f1 = evaluator.evaluate(predictions)\n",
    "    \n",
    "    evaluator = MulticlassClassificationEvaluator(predictionCol=predictionCol, labelCol=labelCol, metricName=ACCURACY_METRIC_NAME)\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    \n",
    "    return {\"ROC\": roc, \"F1\": f1, \"Accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(train_data, test_data):\n",
    "    lr = LogisticRegression(maxIter=MAX_ITER_LR)\n",
    "    paramGrid_lr = ParamGridBuilder().build()\n",
    "    \n",
    "    crossval_lr = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid_lr, evaluator=BinaryClassificationEvaluator(), numFolds=NUM_FOLDS)\n",
    "    cvModel_lr = crossval_lr.fit(train_data)\n",
    "    \n",
    "    best_model_lr = cvModel_lr.bestModel\n",
    "    train_fit_lr = best_model_lr.transform(train_data)\n",
    "    train_summary = evaluate_model(train_fit_lr)\n",
    "    \n",
    "    predictions_lr = cvModel_lr.transform(test_data)\n",
    "    test_summary = evaluate_model(predictions_lr)\n",
    "\n",
    "    details_table(train_fit_lr, predictions_lr)\n",
    "    \n",
    "    return train_summary, test_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession.builder.appName(\"SocialApp\").getOrCreate()\n",
    "    # Use the file Url variable to upload the CSV file\n",
    "    df = read_file(fileUrl, spark)\n",
    "    df = pre_process(df)\n",
    "    train_data, test_data = train_test_split(df)\n",
    "    train_summary, test_summary = logistic_regression(train_data, test_data)\n",
    "    spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
